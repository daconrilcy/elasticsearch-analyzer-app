# Validateur DSL des Mappings Elasticsearch

## Vue d'ensemble

Ce module impl√©mente un validateur unifi√© pour le DSL (Domain Specific Language) de mapping qui permet de transformer des donn√©es CSV/JSON en index Elasticsearch. Il fournit trois endpoints principaux :

- **Validation** : V√©rifie la syntaxe et la coh√©rence du mapping DSL
- **Compilation** : G√©n√®re le mapping Elasticsearch exploitable
- **Dry-run** : Ex√©cute un test sur un √©chantillon de donn√©es

## Architecture

```
app/domain/mapping/
‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îî‚îÄ‚îÄ common/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ mapping.schema.json    # Sch√©ma JSON Schema Draft 2020-12
‚îÇ       ‚îî‚îÄ‚îÄ json_validator.py      # Validateur avec post-r√®gles m√©tier
‚îú‚îÄ‚îÄ schemas.py                     # Mod√®les Pydantic pour l'API
‚îî‚îÄ‚îÄ services.py                    # Service de validation et compilation

app/api/v1/
‚îî‚îÄ‚îÄ mappings.py                    # Endpoints FastAPI
```

## Endpoints API

### 1. Validation (`POST /api/v1/mappings/validate`)

Valide un mapping DSL et retourne les erreurs/warnings.

**Requ√™te :**
```json
{
  "index": "demo",
  "globals": {
    "nulls": [],
    "bool_true": [],
    "bool_false": [],
    "decimal_sep": ",",
    "thousands_sep": " ",
    "date_formats": [],
    "default_tz": "Europe/Paris",
    "empty_as_null": true,
    "preview": {"sample_size": 10, "seed": 1}
  },
  "id_policy": {
    "from": ["id"],
    "op": "concat",
    "sep": ":",
    "on_conflict": "error"
  },
  "fields": [
    {
      "target": "name",
      "type": "text",
      "input": [{"kind": "column", "name": "full_name"}],
      "pipeline": [{"op": "trim"}]
    }
  ]
}
```

**R√©ponse :**
```json
{
  "errors": [],
  "warnings": [],
  "field_stats": [],
  "compiled": null
}
```

### 2. Compilation (`POST /api/v1/mappings/compile`)

Compile le mapping DSL en mapping Elasticsearch exploitable.

**Param√®tres :**
- `includePlan` (query) : Inclure le plan d'ex√©cution (optionnel)

**R√©ponse :**
```json
{
  "settings": {...},
  "mappings": {
    "properties": {
      "name": {"type": "text"},
      "age": {"type": "long"}
    }
  },
  "execution_plan": [
    {
      "target": "name",
      "input": [{"kind": "column", "name": "full_name"}],
      "ops": [{"op": "trim"}]
    }
  ]
}
```

### 3. Inf√©rence de Types (`POST /api/v1/mappings/infer-types`)

Inf√®re automatiquement les types Elasticsearch √† partir d'un √©chantillon de donn√©es.

**Requ√™te :**
```json
{
  "rows": [
    {"a": "12", "b": "2024-01-01", "c": "oui", "d": "Paris", "e": "1.2.3.4"}
  ],
  "globals": {
    "nulls": [],
    "bool_true": ["oui"],
    "bool_false": ["non"],
    "decimal_sep": ",",
    "thousands_sep": " ",
    "date_formats": ["yyyy-MM-dd"],
    "default_tz": "Europe/Paris",
    "empty_as_null": true
  }
}
```

**R√©ponse :**
```json
{
  "field_stats": [
    {
      "source": "a",
      "non_null": 1,
      "null_rate": 0.0,
      "unique": 1,
      "unique_ratio": 1.0,
      "avg_len": 2.0,
      "max_len": 2,
      "examples": ["12"],
      "candidates": {"double": 1.0, "integer": 0.9}
    }
  ],
  "suggestions": [
    {
      "source": "a",
      "es_type": "double",
      "confidence": 1.0,
      "reasons": ["1/1 num√©riques", "1/1 entiers"],
      "extras": {}
    }
  ]
}
```

### 4. Estimation de Taille (`POST /api/v1/mappings/estimate-size`)

Estime la taille de l'index et recommande le nombre de shards.

**Requ√™te :**
```json
{
  "mapping": {
    "fields": [
      {"target": "name", "type": "text"},
      {"target": "status", "type": "keyword"},
      {"target": "price", "type": "double"}
    ]
  },
  "field_stats": [
    {"target": "name", "avg_len": 20},
    {"target": "status", "avg_len": 6}
  ],
  "num_docs": 1000000,
  "replicas": 1,
  "target_shard_size_gb": 30
}
```

**R√©ponse :**
```json
{
  "per_doc_bytes": 200,
  "primary_size_bytes": 200000000,
  "total_size_bytes": 400000000,
  "recommended_shards": 1,
  "target_shard_size_gb": 30,
  "breakdown": [
    {
      "target": "name",
      "type": "text",
      "per_doc_bytes": 30
    }
  ]
}
```

### 3. Dry-run (`POST /api/v1/mappings/dry-run`)

Ex√©cute un test du mapping sur un √©chantillon de donn√©es.

**R√©ponse :**
```json
{
  "docs_preview": [],
  "issues": []
}
```

## Endpoints de Test

Pour faciliter les tests, des endpoints sans authentification sont disponibles :

- `POST /api/v1/mappings/validate/test`
- `POST /api/v1/mappings/compile/test`
- `POST /api/v1/mappings/dry-run/test`
- `POST /api/v1/mappings/infer-types/test`
- `POST /api/v1/mappings/estimate-size/test`

## üéØ **Gains UX Imm√©diats**

### **Inf√©rence ‚Üí Mapping Builder**
- **Pr√©-remplissage automatique** des types ES
- **Proposition de multi-fields** : `*.raw` auto si `text`
- **Format de date** sugg√©r√© selon les donn√©es
- **Confidence score** pour chaque suggestion
- **Raisons d√©taill√©es** de chaque choix

### **Estimation de Taille**
- **Card de dimensionnement** dans l'√©cran "Validation"
- **Affichage** : ~ X Go primaires, ~ Y Go total
- **Recommandation** : Z shards sugg√©r√©s
- **Breakdown** par champ pour optimisation
- **Ajustement** du nombre de r√©plicas

## Sch√©ma DSL

Le mapping DSL suit cette structure :

### Champs obligatoires
- `index` : Nom de l'index Elasticsearch
- `globals` : Configuration globale (nulls, bool√©ens, formats, etc.)
- `id_policy` : Politique de g√©n√©ration des IDs
- `fields` : D√©finition des champs et transformations

### Types de champs support√©s
- `text`, `keyword`, `long`, `double`, `date`, `boolean`
- `geo_point`, `geo_shape`

### Op√©rations de pipeline
- `trim`, `lowercase`, `uppercase`
- `split`, `replace`
- `parse_date`, `parse_geo`, `parse_number`, `parse_boolean`

### Multi-fields
Support des sous-champs avec analyseurs/normaliseurs sp√©cifiques.

## Validation

### Validation JSON Schema
- V√©rification de la structure et des types
- Validation des patterns et contraintes
- Gestion des propri√©t√©s requises

### Post-r√®gles m√©tier
- **Unicit√© des targets** : Pas de doublons de chemins de champs
- **R√©f√©rences valides** : Analyseurs et normaliseurs doivent exister
- **Collisions multi-fields** : V√©rification des noms de sous-champs
- **Politique d'ID** : Obligatoire pour √©viter les conflits
- **Collision .raw** : Protection contre les conflits avec les champs r√©serv√©s

## Compilation

La compilation transforme le DSL en mapping Elasticsearch :

1. **Types de base** : Conversion directe des types DSL vers types ES
2. **Multi-fields** : G√©n√©ration de la structure `fields` ES
3. **Imbrication** : Support des chemins `a.b.c` via `properties` imbriqu√©s
4. **Analyseurs/Normaliseurs** : Transmission directe des configurations
5. **Options** : Int√©gration des param√®tres sp√©cifiques aux types

## Tests

```bash
# Lancer tous les tests
python -m pytest tests/api/v1/test_mappings.py -v

# Lancer un test sp√©cifique
python -m pytest tests/api/v1/test_mappings.py::test_validate_minimal -v

# Avec sortie d√©taill√©e
python -m pytest tests/api/v1/test_mappings.py -v -s
```

## D√©monstration

Un script de d√©monstration est disponible :

```bash
python test_mapping_dsl.py
```

Ce script teste tous les endpoints avec un mapping DSL complet.

## Utilisation

### 1. D√©marrer l'application
```bash
cd backend
uvicorn main:app --reload
```

### 2. Tester la validation
```bash
curl -X POST "http://localhost:8000/api/v1/mappings/validate/test" \
  -H "Content-Type: application/json" \
  -d @mapping_example.json
```

### 3. Compiler un mapping
```bash
curl -X POST "http://localhost:8000/api/v1/mappings/compile/test?includePlan=true" \
  -H "Content-Type: application/json" \
  -d @mapping_example.json
```

## Extensions futures

- **Ex√©cution de pipeline** : Impl√©mentation des op√©rations de transformation
- **Statistiques de champs** : Analyse des donn√©es pour optimiser les mappings
- **Validation avanc√©e** : R√®gles m√©tier suppl√©mentaires
- **G√©n√©ration de code** : Export vers d'autres formats (Python, Java, etc.)
- **Interface graphique** : √âditeur visuel du DSL

## D√©pendances

- `jsonschema>=4.25.0` : Validation JSON Schema
- `fastapi` : Framework web
- `pydantic` : Validation des donn√©es
- `pytest` : Tests unitaires
